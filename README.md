# ğŸ“„ Document Q&A Chatbot (Groq + LangChain + Streamlit)

A **conversational AI chatbot** that lets users **upload documents (PDF/TXT)** and ask questions about them.  
It uses:

- **Groq Cloud LLMs** ğŸš€ for superfast responses  
- **LangChain** ğŸ”— for chaining prompts, memory, and retrieval  
- **HuggingFace Embeddings** ğŸ¤— + **FAISS** for local vector search  
- **Streamlit** ğŸ¨ for the interactive UI  

---

## âœ¨ Features
- ğŸ“¤ Upload a **PDF/TXT file**
- ğŸ¤– Ask **questions** about the uploaded document
- ğŸ§  **Conversational memory** to maintain context
- ğŸ” **Retrieval-Augmented Generation (RAG)** using FAISS vector search
- âš¡ **Groq-powered LLM** for fast and accurate answers
- ğŸ›ï¸ Modular backend (`llm.py`, `chains.py`, `vectorstore.py`)  

---

## ğŸ—ï¸ Project Structure
```
qa_chatbot/
â”‚â”€â”€ app.py                   # Streamlit app (UI)
â”‚â”€â”€ requirements.txt         # Dependencies
â”‚â”€â”€ .env                     # Secrets (API keys)
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ config.py            # Load environment variables
â”‚   â”œâ”€â”€ llm.py               # Groq LLM setup
â”‚   â”œâ”€â”€ vectorstore.py       # PDF/Text loader + FAISS embeddings
â”‚   â”œâ”€â”€ memory.py            # Chat memory handler
â”‚   â””â”€â”€ chains.py            # Q&A retrieval chain
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample.txt           # Example document
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_chain.py        # Unit tests
```

---

## âš™ï¸ Installation & Setup

### 1. Clone Repository
```bash
git clone https://github.com/your-username/qa_chatbot.git
cd qa_chatbot
```

### 2. Create Virtual Environment (Optional but Recommended)
```bash
python3 -m venv venv
source venv/bin/activate     # On Linux/Mac
venv\Scripts\activate        # On Windows
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Set Environment Variables
Create a `.env` file in the project root:

```ini
GROQ_API_KEY=your_groq_api_key_here
```

ğŸ‘‰ Get your Groq API key from [Groq Console](https://console.groq.com/).

---

## â–¶ï¸ Running the App
Start the Streamlit server:
```bash
streamlit run app.py
```

Open [http://localhost:8501](http://localhost:8501) in your browser. ğŸ‰

---

## ğŸ–¥ï¸ Usage
1. Upload a **PDF** or **TXT** file.  
2. Type your question in the chat box.  
3. The chatbot will:
   - Embed and index the document with **HuggingFace + FAISS**  
   - Retrieve the most relevant chunks  
   - Pass them into a **Groq LLM** via LangChain  
   - Return a natural language answer  

---

## ğŸ”§ Tech Stack
- **LLM**: Groq Cloud (e.g., `llama-3.3-70b-versatile`)
- **Framework**: LangChain
- **Embeddings**: HuggingFace (`all-MiniLM-L6-v2`)
- **Vector DB**: FAISS
- **Frontend**: Streamlit
- **Memory**: LangChain ConversationBufferMemory

---

## ğŸ“Œ Example
Upload a **Company Policy PDF** and ask:

```
Q: What is the annual leave policy?
A: Employees are entitled to 24 paid leaves per year...
```

---

## ğŸš€ Future Enhancements
- ğŸ“‘ Support **DOCX/Word uploads**
- ğŸ—„ï¸ Multi-file ingestion
- ğŸ’¾ Persist vector DB for re-using documents
- ğŸŒ Add external tools (Web Search, SQL DB)
- ğŸ”’ Authentication for multi-user usage

---

## ğŸ§ª Testing
Run unit tests:
```bash
pytest tests/
```

---

## ğŸ¤ Contributing
Contributions are welcome!  
- Fork the repo  
- Create a new branch  
- Commit changes  
- Open a Pull Request  

---

## ğŸ“œ License
This project is licensed under the **MIT License**.  
